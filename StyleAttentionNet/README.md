# StyleAttentionNetwork

## Summary
![network](https://github.com/SerialLain3170/ImageStyleTransfer/blob/master/StyleAttentionNet/network.png)

- Original paper is [here](https://arxiv.org/pdf/1812.02342.pdf)
- The authors of paper propose a style attention layer which uses features extracted by VGG.
- The weights of two identity losses in this implementation are swapped described in paper.  [Reference](https://github.com/dypark86/SANET/issues/1)

## Usage
### Training Phase
Execute the command line below.
```bash
$ python train.py --con_path <CON_PATH> --sty_path <STY_PATH>
```
`CON_PATH`: directory which contains content images  
`STY_PATH`: directory which conatins style images  

### Inference Phase
Execute the command line below.
```bash
$ python inference.py --con_path <CON_PATH> --sty_path <STY_PATH> --model <MODEL_PATH>
```
`CON_PATH`: directory which contains content images  
`STY_PATH`: directory which conatins style images  
`MODEL_PATH`: path to trained model file

## Result
Image generated by my development environment is as follows.
![result](https://github.com/SerialLain3170/ImageStyleTransfer/blob/master/StyleAttentionNet/transfer_result.png)
