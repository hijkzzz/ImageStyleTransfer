# CycleGAN

## Summary
![cyclegan](https://github.com/SerialLain3170/GAN-papers/blob/master/makegirlsmoe/cyclegan.png)

- Conventional the method of style transfer like pix2pix needs a lot of paired data. But, CycleGAN is able to deal with unpaired data. 
- There are two generators and two discriminators.
- In addition to adversarial loss, the authors of this paper propose cycle-consistency loss which caculates l1 loss between and source image and go-and-back image.

## Usage

### Training Phase
Execute the command line below.
```bash
$ python train.py --src_path <SRC_PATH> --tgt_path <TGT_PATH>
```
`SRC_PATH` and `TGT_PATH` are direcotry which contains training images of each domain.

### Inference Phase
Execute the command line below.
```bash
$ python inference.py --src_path <SRC_PATH> --model <MODEL_PATH>
```
`SRC_PATH`: directory which contains test images  
`MODEL_PATH`: trained model path

## Result
Image generated by my development environment is below. Using CycleGAN, I implement the conversion of character's hair color.
![image](https://github.com/SerialLain3170/Style-Transfer/blob/master/CycleGAN/result.jpg)
- Input size: 128 * 128
- Batch size: 10
- Using Adam as optimizer
- The weight of adversarial loss is 3.0
