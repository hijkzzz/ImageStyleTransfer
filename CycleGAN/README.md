# CycleGAN

## Summary
![cyclegan](https://github.com/SerialLain3170/GAN-papers/blob/master/makegirlsmoe/cyclegan.png)

- Conventional the method of style transfer like pix2pix needs a lot of paired data. But, CycleGAN is able to deal with unpaired data. 
- There are two generators and two discriminators.
- In addition to adversarial loss, the authors of this paper propose cycle-consistency loss which caculates l1 loss between and source image and go-and-back image.

## Usage
Execute command line below.
```bash
$ python cyclegan.py --lam2 <WEIGHT>
```
I designate WEIGHT to the weight of adversarial loss.

## Result
Image generated by my development environment is below. Using CycleGAN, I implement the conversion of character's hair color.
![image](https://github.com/SerialLain3170/Style-Transfer/blob/master/CycleGAN/result.jpg)
- Input size: 128 * 128
- Batch size: 10
- Using Adam as optimizer
- The weight of adversarial loss is 3.0
